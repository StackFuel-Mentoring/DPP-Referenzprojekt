{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for Hyperparameter Optimization\n",
    "\n",
    "Since the base model with default values for hyperparameters shows already satisfying metrics, this is just a try to improve the results by using Bayesian Optimization for hyperparameter tuning.\n",
    "\n",
    "Bayesian Optimization is used to optimize the R2 in a first attempt, and in a second attempt to optimize the RMSE. Metrics and learning curves are used for comparison.\n",
    "\n",
    "The results are a bit disappointing. The trained models show lower metric scores than the base model.\n",
    "\n",
    "The number of iterations is limited to 20 due to resource restrictions. Therefore, it is possible to get a better model with an increased number of iterations such as 50 or 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# data preparation, modeling, intepretation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# For Bayesian Optimization\n",
    "import time\n",
    "import optuna \n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# importing plotly and enable jupyter notebooks for showing optuna visualisations \n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "df = pd.read_csv('data/Clean_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "df_train, df_test = train_test_split(df, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print('df_train: ', df_train.shape)\n",
    "print('df_test: ', df_test.shape)\n",
    "\n",
    "# Second Train-Test-Split for val/aim data\n",
    "df_test, df_val = train_test_split(df_test, test_size=0.33, random_state = 42)\n",
    "\n",
    "print('df_test: ', df_test.shape)\n",
    "print('df_val: ', df_val.shape)\n",
    "\n",
    "# splitting train data into features and target\n",
    "features_train = df_train.drop('price', axis = 1)\n",
    "target_train = df_train['price']\n",
    "\n",
    "# splitting test data into features and target\n",
    "features_test = df_test.drop('price', axis = 1)\n",
    "target_test = df_test['price']\n",
    "\n",
    "# splitting val data into features and target\n",
    "features_val = df_val.drop('price', axis = 1)\n",
    "target_val = df_val['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data function\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "        Returns clean data frame\n",
    "        Args: DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # dropping 'Unnamed_ 0' column\n",
    "    df = df.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "    # dropping flight numbers\n",
    "    df = df.drop('flight', axis = 1)\n",
    "\n",
    "    #changing class into binary\n",
    "    df.loc[:, 'class'] = df.loc[:, 'class'].replace({'Business': 0, 'Economy': 1})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying clean_data function on train data\n",
    "features_train_cleaned = clean_data(features_train)\n",
    "display(features_train_cleaned.head())\n",
    "\n",
    "#applying clean_data function on test and val data\n",
    "features_test_cleaned = clean_data(features_test)\n",
    "features_val_cleaned = clean_data(features_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization on R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining categorical and numerical columns\n",
    "cat_cols = ['airline', 'source_city', 'departure_time', 'stops',\n",
    "            'arrival_time', 'destination_city']\n",
    "\n",
    "num_cols = ['duration', 'days_left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining pipelines for each step\n",
    "# numerical\n",
    "numeric_transformer = Pipeline([('scaler', StandardScaler())])\n",
    "\n",
    "# categorical\n",
    "categorical_transformer = Pipeline([('ohe', OneHotEncoder(sparse_output = False, handle_unknown = 'ignore'))])\n",
    "\n",
    "# combining each pipeline step into ColumnTransformer for data preparation\n",
    "preprocessor = ColumnTransformer([('num', numeric_transformer, num_cols),\n",
    "                                  ('cat', categorical_transformer, cat_cols)], remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreating DataFrame back after preprocessing\n",
    "features_train_preprocessed = preprocessor.fit_transform(features_train_cleaned)\n",
    "\n",
    "ohe_col_list = preprocessor.transformers_[1][1].named_steps['ohe'].get_feature_names_out(cat_cols)\n",
    "features_train_preprocessed = pd.DataFrame(features_train_preprocessed, columns = num_cols + list(ohe_col_list) + ['class'], index = features_train.index)\n",
    "display(features_train_preprocessed.head())\n",
    "\n",
    "features_test_preprocessed = preprocessor.transform(features_test_cleaned)\n",
    "features_test_preprocessed = pd.DataFrame(features_test_preprocessed, columns = num_cols + list(ohe_col_list) + ['class'], index = features_test.index)\n",
    "display(features_test_preprocessed.head())\n",
    "\n",
    "features_val_preprocessed = preprocessor.transform(features_val_cleaned)\n",
    "features_val_preprocessed = pd.DataFrame(features_val_preprocessed, columns = num_cols + list(ohe_col_list) + ['class'], index = features_val.index)\n",
    "display(features_val_preprocessed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Optimization on R2\n",
    "def objective(trial):\n",
    "    \"\"\"return maximized f1-score\"\"\"\n",
    "   \n",
    "    # search space\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 250)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "    max_features = trial.suggest_categorical('max_features', choices = ['sqrt', 'log2', None])\n",
    "    min_samples_split = trial.suggest_int(name=\"min_samples_split\", low=2, high=10, step=2)\n",
    "    min_samples_leaf = trial.suggest_int(name=\"min_samples_leaf\", low=1, high=4, step=1)\n",
    "    \n",
    "    params = {'n_estimators': n_estimators,\n",
    "             'max_features': max_features,\n",
    "             'max_depth': max_depth,\n",
    "             'min_samples_split': min_samples_split,\n",
    "             'min_samples_leaf': min_samples_leaf}\n",
    "    \n",
    "    # random forest classifier object \n",
    "    model_rf = RandomForestRegressor(random_state=42, **params)\n",
    "    \n",
    "    # initiating cv\n",
    "    score =  cross_val_score(estimator=model_rf, \n",
    "                             X=features_train_preprocessed, \n",
    "                             y=target_train, \n",
    "                             scoring='r2',\n",
    "                             cv=5,\n",
    "                             n_jobs=-1).mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "# create a study (aim to maximize score) und setting a seed (random_state) for reproduceability\n",
    "study = optuna.create_study(sampler=TPESampler(seed = 42), direction='maximize')\n",
    "\n",
    "# perform hyperparamter tuning (while timing the process)\n",
    "time_start = time.time()\n",
    "# starting optimization process with our defined function and 50 iterations\n",
    "study.optimize(objective, n_trials=20)\n",
    "time_bayesian = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_bayesian = [20, study.best_trial.number, study.best_trial.value, time_bayesian]\n",
    "results_bayesian = pd.DataFrame([values_bayesian], columns = ['Number of iterations', \n",
    "                                                                        'Iteration Number of Optimal Hyperparamters', \n",
    "                                                                        'Score', \n",
    "                                                                        'Time Elapsed (s)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "display(results_bayesian)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model optimized on R2\n",
    "best_params = {'n_estimators': 176, \n",
    "               'max_depth': 15, \n",
    "               'max_features': None, \n",
    "               'min_samples_split': 4, \n",
    "               'min_samples_leaf': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and evaluating predictions on test data\n",
    "best_model = RandomForestRegressor(random_state = 42, **best_params)\n",
    "\n",
    "best_model.fit(features_train_preprocessed, target_train)\n",
    "\n",
    "target_test_pred = best_model.predict(features_test_preprocessed)\n",
    "\n",
    "print('R2: ', r2_score(target_test, target_test_pred))\n",
    "print('RMSE: ', root_mean_squared_error(target_test, target_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating predictions on val data\n",
    "target_val_pred = best_model.predict(features_val_preprocessed)\n",
    "\n",
    "# showing metrics\n",
    "print('R2: ', r2_score(target_val, target_val_pred))\n",
    "print('RMSE: ', root_mean_squared_error(target_val, target_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing learning curve (watch out, it will take some time on the current PC; 16 to 23 minutes)\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=best_model, \n",
    "                                                        X=features_train_preprocessed, \n",
    "                                                        y=target_train, \n",
    "                                                        cv=5, \n",
    "                                                        scoring='r2')\n",
    "\n",
    "train_sizes_lc = train_sizes\n",
    "train_mean_lc = train_scores.mean(axis=1)\n",
    "test_mean_lc = test_scores.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting learning curve\n",
    "fig_lc, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(train_sizes_lc, train_mean_lc, label=\"train\", color = 'red')\n",
    "ax.plot(train_sizes_lc, test_mean_lc, label=\"validation\", color = 'blue')\n",
    "\n",
    "ax.set_title(\"Learning Curve\")\n",
    "ax.set_xlabel(\"Training Set Size\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.legend(loc=\"best\")\n",
    "fig_lc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization on RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization on RMSE\n",
    "def objective(trial):\n",
    "    \"\"\"return maximized f1-score\"\"\"\n",
    "   \n",
    "    # search space\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 250)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "    max_features = trial.suggest_categorical('max_features', choices = ['sqrt', 'log2', None])\n",
    "    min_samples_split = trial.suggest_int(name=\"min_samples_split\", low=2, high=10, step=2)\n",
    "    min_samples_leaf = trial.suggest_int(name=\"min_samples_leaf\", low=1, high=4, step=1)\n",
    "    \n",
    "    params = {'n_estimators': n_estimators,\n",
    "             'max_features': max_features,\n",
    "             'max_depth': max_depth,\n",
    "             'min_samples_split': min_samples_split,\n",
    "             'min_samples_leaf': min_samples_leaf}\n",
    "    \n",
    "    # random forest classifier object \n",
    "    model_rf = RandomForestRegressor(random_state=42, **params)\n",
    "    \n",
    "    # initiating cv\n",
    "    score =  cross_val_score(estimator=model_rf, \n",
    "                             X=features_train_preprocessed, \n",
    "                             y=target_train, \n",
    "                             scoring='neg_root_mean_squared_error',\n",
    "                             cv=5,\n",
    "                             n_jobs=-1).mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "# create a study (aim to maximize score) und setting a seed (random_state) for reproduceability\n",
    "study = optuna.create_study(sampler=TPESampler(seed = 42), direction='maximize')\n",
    "\n",
    "# perform hyperparamter tuning (while timing the process)\n",
    "time_start = time.time()\n",
    "# starting optimization process with our defined function and 50 iterations\n",
    "study.optimize(objective, n_trials=20)\n",
    "time_bayesian = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_bayesian = [20, study.best_trial.number, study.best_trial.value, time_bayesian]\n",
    "results_bayesian = pd.DataFrame([values_bayesian], columns = ['Number of iterations', \n",
    "                                                                        'Iteration Number of Optimal Hyperparamters', \n",
    "                                                                        'Score', \n",
    "                                                                        'Time Elapsed (s)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model\n",
    "best_params = {'n_estimators': 176, \n",
    "               'max_depth': 15, \n",
    "               'max_features': None, \n",
    "               'min_samples_split': 4, \n",
    "               'min_samples_leaf': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and evaluating predictions on test data\n",
    "best_model = RandomForestRegressor(random_state = 42, **best_params)\n",
    "\n",
    "best_model.fit(features_train_preprocessed, target_train)\n",
    "\n",
    "target_test_pred = best_model.predict(features_test_preprocessed)\n",
    "\n",
    "print('R2: ', r2_score(target_test, target_test_pred))\n",
    "print('RMSE: ', root_mean_squared_error(target_test, target_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating predictions on val data\n",
    "target_val_pred = best_model.predict(features_val_preprocessed)\n",
    "\n",
    "# showing metrics\n",
    "print('R2: ', r2_score(target_val, target_val_pred))\n",
    "print('RMSE: ', root_mean_squared_error(target_val, target_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing learning curve (watch out, it will take some time on the current PC; 16 to 23 minutes)\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=best_model, \n",
    "                                                        X=features_train_preprocessed, \n",
    "                                                        y=target_train, \n",
    "                                                        cv=5, \n",
    "                                                        scoring='neg_root_mean_squared_error')\n",
    "\n",
    "train_sizes_lc = train_sizes\n",
    "train_mean_lc = train_scores.mean(axis=1)\n",
    "test_mean_lc = test_scores.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting learning curve\n",
    "fig_lc, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(train_sizes_lc, train_mean_lc, label=\"train\", color = 'red')\n",
    "ax.plot(train_sizes_lc, test_mean_lc, label=\"validation\", color = 'blue')\n",
    "\n",
    "ax.set_title(\"Learning Curve\")\n",
    "ax.set_xlabel(\"Training Set Size\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.legend(loc=\"best\")\n",
    "fig_lc;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
