{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base model\n",
    "\n",
    "A simple base model will be built and tested.\n",
    "Categorical features have been encoded ('flight' excluded), numerical features standardized.\n",
    "No Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "# For Bayesian Optimization\n",
    "import time\n",
    "import optuna \n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# importing plotly and enable jupyter notebooks for showing optuna visualisations \n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "df = pd.read_csv('data/Clean_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "df_train, df_test = train_test_split(df, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print('df_train: ', df_train.shape)\n",
    "print('df_test: ', df_test.shape)\n",
    "\n",
    "# Second Train-Test-Split for val/aim data\n",
    "df_test, df_val = train_test_split(df_test, test_size=0.33, random_state = 42)\n",
    "\n",
    "print('df_test: ', df_test.shape)\n",
    "print('df_val: ', df_val.shape)\n",
    "\n",
    "# splitting train data into features and target\n",
    "features_train = df_train.drop('price', axis = 1)\n",
    "target_train = df_train['price']\n",
    "\n",
    "# splitting test data into features and target\n",
    "features_test = df_test.drop('price', axis = 1)\n",
    "target_test = df_test['price']\n",
    "\n",
    "# splitting val data into features and target\n",
    "features_val = df_val.drop('price', axis = 1)\n",
    "target_val = df_val['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing data types\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data function\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "        Returns clean data frame\n",
    "        Args: DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # dropping 'Unnamed_ 0' column\n",
    "    df = df.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "    # dropping flight numbers\n",
    "    df = df.drop('flight', axis = 1)\n",
    "\n",
    "    #changing class into binary\n",
    "    df.loc[:, 'class'] = df.loc[:, 'class'].replace({'Business': 0, 'Economy': 1})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying clean_data function on train data\n",
    "features_train_cleaned = clean_data(features_train)\n",
    "display(features_train_cleaned.head())\n",
    "\n",
    "#applying clean_data function on test and val data\n",
    "features_test_cleaned = clean_data(features_test)\n",
    "features_val_cleaned = clean_data(features_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation und training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting columns easy for copy-paste ;-) \n",
    "features_train_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining categorical and numerical columns\n",
    "cat_cols = ['airline', 'source_city', 'departure_time', 'stops',\n",
    "            'arrival_time', 'destination_city']\n",
    "\n",
    "num_cols = ['duration', 'days_left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining pipelines for each step\n",
    "# numerical\n",
    "numeric_transformer = Pipeline([('scaler', StandardScaler())])\n",
    "\n",
    "# categorical\n",
    "categorical_transformer = Pipeline([('ohe', OneHotEncoder(sparse_output = False, handle_unknown = 'ignore'))])\n",
    "\n",
    "# combining each pipeline step into ColumnTransformer\n",
    "preprocessor = ColumnTransformer([('num', numeric_transformer, num_cols),\n",
    "                                  ('cat', categorical_transformer, cat_cols)], remainder = 'passthrough')\n",
    "\n",
    "# defining final pipeline\n",
    "pipeline_rf = Pipeline([('preprocessor', preprocessor),\n",
    "                        ('model', RandomForestRegressor(random_state = 42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "pipeline_rf.fit(features_train_cleaned, target_train)\n",
    "\n",
    "# predicting test data\n",
    "target_test_pred = pipeline_rf.predict(features_test_cleaned)\n",
    "\n",
    "# showing metrics\n",
    "print('R2: ', r2_score(target_test, target_test_pred))\n",
    "print('RMSE: ', root_mean_squared_error(target_test, target_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting val data\n",
    "target_val_pred = pipeline_rf.predict(features_val_cleaned)\n",
    "\n",
    "# showing metrics\n",
    "print('R2: ', r2_score(target_val, target_val_pred))\n",
    "print('RMSE: ', root_mean_squared_error(target_val, target_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking cross validation score\n",
    "cv_results = cross_val_score(estimator=pipeline_rf,\n",
    "                            X=features_train_cleaned,\n",
    "                            y=target_train,\n",
    "                            cv=5,\n",
    "                            scoring='r2',\n",
    "                            n_jobs=-1)\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreating DataFrame back after preprocessing\n",
    "features_train_preprocessed = preprocessor.fit_transform(features_train_cleaned)\n",
    "\n",
    "ohe_col_list = preprocessor.transformers_[1][1].named_steps['ohe'].get_feature_names_out(cat_cols)\n",
    "features_train_preprocessed = pd.DataFrame(features_train_preprocessed, columns = num_cols + list(ohe_col_list) + ['class'], index = features_train.index)\n",
    "display(features_train_preprocessed.head())\n",
    "\n",
    "features_test_preprocessed = preprocessor.transform(features_test_cleaned)\n",
    "features_test_preprocessed = pd.DataFrame(features_test_preprocessed, columns = num_cols + list(ohe_col_list) + ['class'], index = features_test.index)\n",
    "display(features_test_preprocessed.head())\n",
    "\n",
    "features_val_preprocessed = preprocessor.transform(features_val_cleaned)\n",
    "features_val_preprocessed = pd.DataFrame(features_val_preprocessed, columns = num_cols + list(ohe_col_list) + ['class'], index = features_val.index)\n",
    "display(features_val_preprocessed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting feature importances from model\n",
    "feature_importance = pd.Series(data=pipeline_rf.steps[1][1].feature_importances_,\n",
    "                               index=features_train_preprocessed.columns)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "\n",
    "# plotting feature importances\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# getting importances from features onyl above 0\n",
    "mask = feature_importance > 0\n",
    "feature_importance = feature_importance.loc[mask]\n",
    "\n",
    "# sorting\n",
    "feature_importance = feature_importance.sort_values()\n",
    "\n",
    "# plotting\n",
    "feature_importance.plot(kind='barh', width=0.8);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing learning curve (watch out, it will take some time; 16 to 23 minutes)\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=RandomForestRegressor(random_state = 42), \n",
    "                                                        X=features_train_preprocessed, \n",
    "                                                        y=target_train, \n",
    "                                                        cv=5, \n",
    "                                                        scoring='r2')\n",
    "\n",
    "train_sizes_lc = train_sizes\n",
    "train_mean_lc = train_scores.mean(axis=1)\n",
    "test_mean_lc = test_scores.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lc, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(train_sizes_lc, train_mean_lc, label=\"train\", color = 'red')\n",
    "ax.plot(train_sizes_lc, test_mean_lc, label=\"validation\", color = 'blue')\n",
    "\n",
    "ax.set_title(\"Learning Curve\")\n",
    "ax.set_xlabel(\"Training Set Size\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.legend(loc=\"best\")\n",
    "fig_lc;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
